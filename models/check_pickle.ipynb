{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b0788d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "INSPECTING: C:/Users/krexw/Documents/GitHub/uas_2/models/male_cluster_model.pkl\n",
      "==================================================\n",
      "Type: <class 'dict'>\n",
      "Keys: ['final_model', 'final_labels', 'best_features', 'best_configuration', 'feature_info', 'dimensionality_reduction', 'all_results', 'metadata', 'data_references', 'scaler']\n",
      "\n",
      "--- final_model ---\n",
      "Type: <class 'sklearn.cluster._kmeans.KMeans'>\n",
      "Cluster model with 10 clusters\n",
      "Cluster centers shape: (10, 512)\n",
      "\n",
      "--- final_labels ---\n",
      "Type: <class 'numpy.ndarray'>\n",
      "Shape: (324,)\n",
      "Dtype: int32\n",
      "\n",
      "--- best_features ---\n",
      "Type: <class 'numpy.ndarray'>\n",
      "Shape: (324, 2)\n",
      "Dtype: float64\n",
      "Sample values (first row): [-21.79756512 -20.87894985]...\n",
      "\n",
      "--- best_configuration ---\n",
      "Type: <class 'dict'>\n",
      "Value preview: {'method': 'K-Means', 'k_value': 10, 'parameters': {'k': 10, 'init': 'k-means++', 'random_state': 42...\n",
      "\n",
      "--- feature_info ---\n",
      "Type: <class 'dict'>\n",
      "Value preview: {'original_face_encodings': array([[-0.32282448, -1.4099492 ,  0.6714958 , ...,  0.81440425,\n",
      "       ...\n",
      "\n",
      "--- dimensionality_reduction ---\n",
      "Type: <class 'dict'>\n",
      "Value preview: {'used': True, 'method': 'Isomap', 'n_components': 2, 'dr_results': {'PCA': {2: {'reduced_features':...\n",
      "\n",
      "--- all_results ---\n",
      "Type: <class 'dict'>\n",
      "Value preview: {'dataframe':                method  n_clusters  n_noise  silhouette_score  \\\n",
      "0      K-means_random ...\n",
      "\n",
      "--- metadata ---\n",
      "Type: <class 'dict'>\n",
      "Value preview: {'timestamp': '2025-06-19 09:19:22', 'total_faces': 324, 'n_clusters_generated': 10, 'gender': 'male...\n",
      "\n",
      "--- data_references ---\n",
      "Type: <class 'dict'>\n",
      "Value preview: {'image_paths': ['C:\\\\Users\\\\krexw\\\\Documents\\\\FREE_PROJECTS\\\\DATING_APP\\\\modeling\\\\dataset\\\\IndoDat...\n",
      "\n",
      "--- scaler ---\n",
      "Type: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "Object attributes: ['copy', 'fit', 'fit_transform', 'get_feature_names_out', 'get_metadata_routing', 'get_params', 'inverse_transform', 'mean_', 'n_features_in_', 'n_samples_seen_']...\n",
      "\n",
      "==================================================\n",
      "INSPECTING: C:/Users/krexw/Documents/GitHub/uas_2/models/female_cluster_model.pkl\n",
      "==================================================\n",
      "Type: <class 'dict'>\n",
      "Keys: ['final_model', 'final_labels', 'best_features', 'best_configuration', 'feature_info', 'dimensionality_reduction', 'all_results', 'metadata', 'data_references', 'scaler']\n",
      "\n",
      "--- final_model ---\n",
      "Type: <class 'sklearn.cluster._kmeans.KMeans'>\n",
      "Cluster model with 10 clusters\n",
      "Cluster centers shape: (10, 512)\n",
      "\n",
      "--- final_labels ---\n",
      "Type: <class 'numpy.ndarray'>\n",
      "Shape: (324,)\n",
      "Dtype: int32\n",
      "\n",
      "--- best_features ---\n",
      "Type: <class 'numpy.ndarray'>\n",
      "Shape: (324, 2)\n",
      "Dtype: float64\n",
      "Sample values (first row): [-21.79756512 -20.87894985]...\n",
      "\n",
      "--- best_configuration ---\n",
      "Type: <class 'dict'>\n",
      "Value preview: {'method': 'K-Means', 'k_value': 10, 'parameters': {'k': 10, 'init': 'k-means++', 'random_state': 42...\n",
      "\n",
      "--- feature_info ---\n",
      "Type: <class 'dict'>\n",
      "Value preview: {'original_face_encodings': array([[-0.32282448, -1.4099492 ,  0.6714958 , ...,  0.81440425,\n",
      "       ...\n",
      "\n",
      "--- dimensionality_reduction ---\n",
      "Type: <class 'dict'>\n",
      "Value preview: {'used': True, 'method': 'Isomap', 'n_components': 2, 'dr_results': {'PCA': {2: {'reduced_features':...\n",
      "\n",
      "--- all_results ---\n",
      "Type: <class 'dict'>\n",
      "Value preview: {'dataframe':                method  n_clusters  n_noise  silhouette_score  \\\n",
      "0      K-means_random ...\n",
      "\n",
      "--- metadata ---\n",
      "Type: <class 'dict'>\n",
      "Value preview: {'timestamp': '2025-06-19 09:23:45', 'total_faces': 324, 'n_clusters_generated': 10, 'gender': 'fema...\n",
      "\n",
      "--- data_references ---\n",
      "Type: <class 'dict'>\n",
      "Value preview: {'image_paths': ['C:\\\\Users\\\\krexw\\\\Documents\\\\FREE_PROJECTS\\\\DATING_APP\\\\modeling\\\\dataset\\\\IndoDat...\n",
      "\n",
      "--- scaler ---\n",
      "Type: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "Object attributes: ['copy', 'fit', 'fit_transform', 'get_feature_names_out', 'get_metadata_routing', 'get_params', 'inverse_transform', 'mean_', 'n_features_in_', 'n_samples_seen_']...\n",
      "Error creating compatible pickle: [Errno 2] No such file or directory: 'models/male_cluster_model_fixed.pkl'\n",
      "Error creating compatible pickle: [Errno 2] No such file or directory: 'models/female_cluster_model_fixed.pkl'\n",
      "\n",
      "==================================================\n",
      "RECOMMENDATIONS:\n",
      "==================================================\n",
      "1. Use the quick fix in your service (Option 1 above)\n",
      "2. If possible, go back to your Jupyter notebook and:\n",
      "   - Extract the original 512D face embeddings\n",
      "   - Save them along with your trained models\n",
      "   - Recreate the pickle files with proper structure\n",
      "3. Update your model loading to use the fixed files\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def inspect_pickle_file(pickle_path):\n",
    "    \"\"\"Inspect what's inside your pickle file\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"INSPECTING: {pickle_path}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    try:\n",
    "        with open(pickle_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        print(f\"Type: {type(data)}\")\n",
    "        \n",
    "        if isinstance(data, dict):\n",
    "            print(f\"Keys: {list(data.keys())}\")\n",
    "            \n",
    "            for key, value in data.items():\n",
    "                print(f\"\\n--- {key} ---\")\n",
    "                print(f\"Type: {type(value)}\")\n",
    "                \n",
    "                if isinstance(value, np.ndarray):\n",
    "                    print(f\"Shape: {value.shape}\")\n",
    "                    print(f\"Dtype: {value.dtype}\")\n",
    "                    if len(value.shape) == 2:\n",
    "                        print(f\"Sample values (first row): {value[0][:5]}...\")\n",
    "                elif isinstance(value, list):\n",
    "                    print(f\"List length: {len(value)}\")\n",
    "                    if len(value) > 0:\n",
    "                        first_item = value[0]\n",
    "                        print(f\"First item type: {type(first_item)}\")\n",
    "                        if isinstance(first_item, np.ndarray):\n",
    "                            print(f\"First item shape: {first_item.shape}\")\n",
    "                elif hasattr(value, 'cluster_centers_'):\n",
    "                    print(f\"Cluster model with {len(value.cluster_centers_)} clusters\")\n",
    "                    print(f\"Cluster centers shape: {value.cluster_centers_.shape}\")\n",
    "                elif hasattr(value, '__dict__'):\n",
    "                    attrs = [attr for attr in dir(value) if not attr.startswith('_')]\n",
    "                    print(f\"Object attributes: {attrs[:10]}...\")  # Show first 10\n",
    "                else:\n",
    "                    print(f\"Value preview: {str(value)[:100]}...\")\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {pickle_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_compatible_pickle(original_data, output_path, original_embeddings_512d=None):\n",
    "    \"\"\"\n",
    "    Create a new pickle file compatible with your service\n",
    "    \n",
    "    Args:\n",
    "        original_data: Data from your original pickle file\n",
    "        output_path: Where to save the new pickle file\n",
    "        original_embeddings_512d: If you have access to original 512D embeddings\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if isinstance(original_data, dict):\n",
    "            # Create new compatible structure\n",
    "            new_data = {}\n",
    "            \n",
    "            # Copy the clustering model\n",
    "            if 'final_model' in original_data:\n",
    "                new_data['final_model'] = original_data['final_model']\n",
    "            elif any('model' in str(key).lower() for key in original_data.keys()):\n",
    "                model_key = next(key for key in original_data.keys() if 'model' in str(key).lower())\n",
    "                new_data['final_model'] = original_data[model_key]\n",
    "            \n",
    "            # If you have original 512D embeddings, add them\n",
    "            if original_embeddings_512d is not None:\n",
    "                new_data['original_face_encodings'] = np.array(original_embeddings_512d)\n",
    "                print(f\"Added original embeddings with shape: {np.array(original_embeddings_512d).shape}\")\n",
    "            \n",
    "            # Copy other useful data\n",
    "            for key, value in original_data.items():\n",
    "                if key not in ['final_model'] and not key.startswith('_'):\n",
    "                    new_data[key] = value\n",
    "            \n",
    "            # Save the new pickle file\n",
    "            with open(output_path, 'wb') as f:\n",
    "                pickle.dump(new_data, f)\n",
    "            \n",
    "            print(f\"Created compatible pickle file: {output_path}\")\n",
    "            return True\n",
    "            \n",
    "        else:\n",
    "            print(\"Original data is not a dictionary, creating new structure...\")\n",
    "            new_data = {\n",
    "                'final_model': original_data,\n",
    "                'original_face_encodings': original_embeddings_512d if original_embeddings_512d is not None else None\n",
    "            }\n",
    "            \n",
    "            with open(output_path, 'wb') as f:\n",
    "                pickle.dump(new_data, f)\n",
    "            \n",
    "            print(f\"Created new pickle structure: {output_path}\")\n",
    "            return True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating compatible pickle: {e}\")\n",
    "        return False\n",
    "\n",
    "# Usage example:\n",
    "def fix_your_pickle_files():\n",
    "    \"\"\"Main function to fix your pickle files\"\"\"\n",
    "    \n",
    "    # Inspect current files\n",
    "    male_data = inspect_pickle_file('C:/Users/krexw/Documents/GitHub/uas_2/models/male_cluster_model.pkl')\n",
    "    female_data = inspect_pickle_file('C:/Users/krexw/Documents/GitHub/uas_2/models/female_cluster_model.pkl')\n",
    "    \n",
    "    # If you don't have original 512D embeddings, we'll work with what we have\n",
    "    # This creates a quick fix version\n",
    "    if male_data:\n",
    "        create_compatible_pickle(\n",
    "            male_data, \n",
    "            'models/male_cluster_model_fixed.pkl'\n",
    "        )\n",
    "    \n",
    "    if female_data:\n",
    "        create_compatible_pickle(\n",
    "            female_data, \n",
    "            'models/female_cluster_model_fixed.pkl'\n",
    "        )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"RECOMMENDATIONS:\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"1. Use the quick fix in your service (Option 1 above)\")\n",
    "    print(\"2. If possible, go back to your Jupyter notebook and:\")\n",
    "    print(\"   - Extract the original 512D face embeddings\")\n",
    "    print(\"   - Save them along with your trained models\")\n",
    "    print(\"   - Recreate the pickle files with proper structure\")\n",
    "    print(\"3. Update your model loading to use the fixed files\")\n",
    "\n",
    "# Run this to inspect your files\n",
    "fix_your_pickle_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
